{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "# import d2l\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_data(w, b, num_examples):\n",
    "    X = torch.normal(0,1,(num_examples,len(w)))\n",
    "    # print(\"X:\",X)\n",
    "    y = torch.matmul(X,w)+b\n",
    "    # print(\"y:\",y)\n",
    "    y += torch.normal(0,0.01,y.shape)\n",
    "    return X,y.reshape((-1,1)) #将y变为n*1的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2,-3.4])\n",
    "# print(true_w.shape)\n",
    "true_b = 4.2\n",
    "features,labels = synthetic_data(true_w,true_b,1000)\n",
    "# print(labels.shape)\n",
    "# labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([-0.6709,  0.7372]) \n",
      "label: tensor([0.3490])\n"
     ]
    }
   ],
   "source": [
    "print('features:', features[0],'\\nlabel:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回小批量样本\n",
    "def data_iter(batch_size,features,labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = indices[i:min(i+batch_size, num_examples)]\n",
    "        # batch_indices = torch.tensor(indices[i:min(i+batch_size,num_examples)])\n",
    "        yield features[batch_indices],labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2078, -0.7279],\n",
      "        [-2.5238,  0.2009],\n",
      "        [ 0.0928,  1.1192],\n",
      "        [ 0.2884, -1.2504],\n",
      "        [-1.9780, -0.4453],\n",
      "        [ 0.9126, -0.0107],\n",
      "        [ 1.3687,  0.2692],\n",
      "        [-1.3664, -0.2164],\n",
      "        [-0.4766,  0.2440],\n",
      "        [-0.8831, -0.0706]]) \n",
      " tensor([[ 6.2444],\n",
      "        [-1.5320],\n",
      "        [ 0.5819],\n",
      "        [ 9.0119],\n",
      "        [ 1.7529],\n",
      "        [ 6.0533],\n",
      "        [ 6.0153],\n",
      "        [ 2.2116],\n",
      "        [ 2.4248],\n",
      "        [ 2.6636]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "for X,y in data_iter(batch_size,features,labels):\n",
    "    print(X,'\\n',y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化模型参数\n",
    "w = torch.normal(0,0.01,size=(2,1),requires_grad=True)\n",
    "b = torch.zeros(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "def linreg(X,w,b):\n",
    "    return torch.matmul(X,w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "def squared_loss(y_hat,y):\n",
    "    return (y_hat - y) ** 2 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#优化算法 随机小批量梯度下降\n",
    "def sgd(params,lr,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,loss0.000773\n",
      "epoch2,loss0.000051\n",
      "epoch3,loss0.000051\n",
      "epoch4,loss0.000052\n",
      "epoch5,loss0.000051\n"
     ]
    }
   ],
   "source": [
    "#模拟三个迭代周期的情形\n",
    "lr = 0.05\n",
    "num_epochs = 5\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter(batch_size,features,labels):\n",
    "        l = loss(net(X,w,b),y)  #计算损失函数，l.shape=(batch_size,1)\n",
    "        l.sum().backward()\n",
    "        sgd([w,b],lr,batch_size)   #更新参数\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features,w,b),labels)\n",
    "        print(f'epoch{epoch+1},loss{float(train_l.mean()):f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374a5e0f4f559eafb15a693a14d5d452fa4b12bb6c1b5b0aa1910e4ecaa304d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 64-bit ('d2l': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
